---
title: "FluVacs Figures - Draft"
author: "Kari and JT"
date: "June 2, 2016"
output:
  github_document:
    toc: true
    toc_depth: 2
---

```{r,include=F}
require(knitr)
require(plyr)
require(ggplot2)
require(reshape2)
require(ggplot2)
require(ggdendro)
require(grid)
opts_chunk$set(fig.align="center",warning=FALSE,tidy=T, fig.width=5,fig.height=4,cache = T,echo=F)
theme_set(new = theme_classic()+ theme(
axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'))) # to make nice plots
source("../scripts/useful_functions.R") # useful functions adapted largley from HIVE work
```


# Initial data processing

So after all that work we are left with all the samples (all seasons) in all.df and only those variants from high quality data in all.qual.df. This includes samples with >10^5^ genomes per microliter or > 10^3^ genomes per microliter but were sequenced in duplicate.


```{r,titers}
# read in the csvs and add a season column to use later
titer.2004.5<-read.csv("../Titers_status_2004-2005.csv",stringsAsFactors = F)
titer.2004.5$season<-"04-05"
titer.2005.6<-read.csv("../Titers_status_2005-2006.csv",stringsAsFactors = F)
titer.2005.6$season<-"05-06"
titer.2007.8<-read.csv("../Titers_status_2007-2008.csv",stringsAsFactors = F)
titer.2007.8$season<-"07-08"
```

```{r}
meta.2007.08<-read.csv("../data/raw/2007_2008.meta.csv",stringsAsFactors = F)
```

```{r, variant_calls}

var.2007.8<-read.csv("../data/processed/Run_1293/Variants/all.sum.csv",stringsAsFactors = F)
x<-read.csv("../data/processed/Run_1304/Variants/all.sum.csv",stringsAsFactors = F) # the rest of these samples
var.2007.8<-rbind(var.2007.8,x) # combine both runs
#other.seasons<-read.csv("../data/processed/Run_1412/Variants/all.sum.csv",stringsAsFactors = F)


# var.2004.5.df<-processing(data.df = other.seasons,meta.df = titer.2004.5,pval = 0.01,phred = 35,mapq = 30,read_cut = c(32,94))
# 
# var.2004.5.df<-subset(var.2004.5.df,season=="04-05")
# var.2005.6.df<-processing(data.df = other.seasons,meta.df = titer.2005.6,pval = 0.01,phred = 35,mapq = 30,read_cut = c(32,94))
# var.2005.6.df<-subset(var.2005.6.df,season=="05-06")
# 
 var.2007.8.df<-processing(data.df = var.2007.8,meta.df = meta.2007.08,pval = 0.01,phred = 35,mapq = 30,read_cut = c(32,94))
# 
# all.df<-rbind(var.2004.5.df,var.2005.6.df)
# all.df<-rbind(all.df,var.2007.8.df)
# 
# all.df<-subset(all.df,freq.var>=0.01)
# ##### Now for the duplicate runs #######
# 
# var.2004.5.df2<-read.csv("../data/processed/2004_2005/Variants/all.sum.csv",stringsAsFactors = F)
# var.2004.5.df2<-processing(data.df = var.2004.5.df2,meta.df = titer.2004.5,pval = 0.01,phred = 35,mapq = 30,read_cut = c(32,94))
# 
# var.2005.6.df2<-read.csv("../data/processed/2005-2006/Variants/all.sum.csv",stringsAsFactors = F)
# var.2005.6.df2<-processing(data.df = var.2005.6.df2,meta.df = titer.2005.6,pval = 0.01,phred = 35,mapq = 30,read_cut = c(32,94))

var.2007.8.df2<-read.csv("../data/processed/2007-2008/Variants/all.sum.csv",stringsAsFactors = F)
var.2007.8.df2<-processing(data.df = var.2007.8.df2,meta.df = titer.2007.8,pval = 0.01,phred = 35,mapq = 30,read_cut = c(32,94))

### Join duplicates #####

# dups.2004.5<-join_dups(data1.df = var.2004.5.df,data2.df = var.2004.5.df2)
# dups.2005.6<-join_dups(data1.df = var.2005.6.df,data2.df = var.2005.6.df2)
dups.2007.8<-join_dups(data1.df = var.2007.8.df,data2.df = var.2007.8.df2)

##### Merge duplicates with intial data that was >1e5

# qual.2004.5<-high_qual(data1.df = var.2004.5.df,dups.df = dups.2004.5,titer = 1e3) # only duplicates above 1e3 kept
# qual.2005.6<-high_qual(data1.df = var.2005.6.df,dups.df = dups.2005.6,titer = 1e3)
qual.2007.8<-high_qual(data1.df = var.2007.8.df,dups.df = dups.2007.8,titer = 1e3)
qual.2007.8<-subset(qual.2007.8,freq.var>=0.01 & freq.var<=0.99)

# all.qual.df<-rbind(qual.2004.5,qual.2005.6)
# all.qual.df<-rbind(all.qual.df,qual.2007.8)
# 
# all.qual.df<-subset(all.qual.df,freq.var>=0.01 & freq.var<=0.99)

```

```{r}
gm_mean = function(x, na.rm=TRUE, zero.propagate = FALSE){ # from http://stackoverflow.com/questions/2602583/geometric-mean-is-there-a-built-in
  if(any(x < 0, na.rm = TRUE)){
    return(NaN)
  }
  if(zero.propagate){
    if(any(x == 0, na.rm = TRUE)){
      return(0)
    }
    exp(mean(log(x), na.rm = na.rm))
  } else {
    exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
  }
}

var.2007.8.df<-mutate(var.2007.8.df,responder.HA=HAI.WI.30.post.vax>40,responder.NA=NAI.WI.30.post.vax>40,HAI.geo=HAI.WI.30.post.vax>gm_mean(HAI.WI.30.post.vax),NAI.geo=gm_mean(NAI.WI.30.post.vax))

qual.2007.8<-mutate(qual.2007.8,responder.HA=HAI.WI.30.post.vax>40,responder.NA=NAI.WI.30.post.vax>40,HAI.geo=HAI.WI.30.post.vax>gm_mean(HAI.WI.30.post.vax),NAI.geo=NAI.WI.30.post.vax>gm_mean(NAI.WI.30.post.vax))
```
#Figure 3 Coverage plots

These are just from the first runs. I'm not including the duplicates here - should I? These have a sliding window of 100 with a step of 100 no overlap.

```{r,coverage}
cov.2007.8<-rbind(read.csv("../data/processed/Run_1293/deepSNV/all.coverage.csv",stringsAsFactors = F),read.csv("../data/processed/Run_1304/deepSNV/all.coverage.csv",stringsAsFactors = F))

other.seasons.cov<-read.csv("../data/processed/Run_1412/deepSNV/all.coverage.csv",stringsAsFactors = F)


cov.2004.5<-subset(other.seasons.cov,Id %in% titer.2004.5$Sample)
cov.2005.6<-subset(other.seasons.cov,Id %in% titer.2005.6$Sample)


cov.plot.04.05<-cov_plot(cov.2004.5,"2004-2005",100,100)
cov.plot.04.05

cov.plot.05.06<-cov_plot(cov.2005.6,"2005-2006",100,100)
cov.plot.05.06

cov.plot.07.08<-cov_plot(cov.2007.8,"2007-2008",100,100)
cov.plot.07.08

```

If we plot on a log scale the bars are well above 0. 

```{r}
cov.plot.07.08+scale_y_log10(breaks=c(1,10,100,1000,10000,100000))
```

# Figure 5 

High quality is >10^5^ or >10^3^ sequenced in duplicate
Currently I am making these plots with just the 2007-2008 samples. Once I have the meta data sorted for the other seasons it will be trivial to add them in. 

# Frequency of Variants

These are the variants between 1-99%. each bin is 1% wide. The y axis is log scaled which in ggplot leads to a problem when there are no observations (lines below axis). I can remove these before publication.
```{r}
ggplot(subset(var.2007.8.df,freq.var<=0.99 & freq.var>=0.01),aes(x=freq.var))+geom_histogram(color="white",binwidth = 0.01)+scale_y_log10() + ggtitle("All samples")
ggplot(subset(qual.2007.8,freq.var<=0.99& freq.var>=0.01),aes(x=freq.var))+geom_histogram(color="white",binwidth = .01)+scale_y_log10() + ggtitle("Only high quality samples")

```

## SNV count per sample

```{r,snv_sample}
count_muts<-function(data.df){
  inter<-ddply(data.df,~Id+Intervention+season,summarize,iSNV=length(mutation))
  inter$variable="Intervention"
  names(inter)[2]<-"quality"
  
  HA.r<-ddply(data.df,~Id+responder.HA+season,summarize,iSNV=length(mutation))
  HA.r$variable='responder.HA'
  names(HA.r)[2]<-"quality"
  out<-rbind(inter,HA.r)
  
  NA.r<-ddply(data.df,~Id+responder.NA+season,summarize,iSNV=length(mutation))
  NA.r$variable="responder.NA"
  names(NA.r)[2]<-"quality"
  out<-rbind(out,NA.r)
  
  HA.geo<-ddply(data.df,~Id+HAI.geo+season,summarize,iSNV=length(mutation))
  HA.geo$variable="geometric HA"
  names(HA.geo)[2]<-"quality"
  out<-rbind(out,HA.geo)
  
  NA.geo<-ddply(data.df,~Id+NAI.geo+season,summarize,iSNV=length(mutation))
  NA.geo$variable<-"geometric NA"
  names(NA.geo)[2]<-"quality"
  out<-rbind(out,NA.geo)
}


all.snv<-count_muts(var.2007.8.df)
qual.snv<-count_muts(qual.2007.8)


```

### iSNV
### Whole Genome

```{r}
dot_plots<-function(df,var){
out<-ggplot(data=subset(all.snv,variable==var),aes(y=iSNV,x=quality))+geom_dotplot(stackdir = "center",binaxis = 'y')+ylab("Number of SNV")+ggtitle("All data")+xlab(var)
print(out)
}

dot_plots(all.snv,"Intervention")
dot_plots(all.snv,"responder.HA")
dot_plots(all.snv,"responder.NA")
dot_plots(all.snv,"geometric HA")
dot_plots(all.snv,"geometric NA")


```

#### High quality

```{r}
dot_plots(qual.snv,"Intervention")
dot_plots(qual.snv,"responder.HA")
dot_plots(qual.snv,"responder.NA")
dot_plots(qual.snv,"geometric HA")
dot_plots(qual.snv,"geometric NA")
```

### HA NA

```{r}
all.ha.na.snv<-count_muts(subset(var.2007.8.df,chr %in%c("HA","N_A","NR")))
ggplot(data=all.ha.na.snv,aes(y=iSNV,x=Intervention))+geom_dotplot(stackdir = "center",binaxis = 'y')+ylab("Number of SNV")+ggtitle("All data")
```

#### High quality

```{r}
qual.ha.na.snv<-count_muts(subset(qual.2007.8,chr %in%c("HA","N_A","NR")))

ggplot(data=qual.ha.na.snv,aes(y=iSNV,x=Intervention))+geom_dotplot(stackdir = "center",binaxis = 'y')+ylab("Number of SNV")+ggtitle("High quality data")
```

# Table 4
Average iSNV/ segment

All data 
```{r}
chr_muts<-function(data.df){
  ddply(data.df,~Intervention+chr,summarize,iSNV=round(length(mutation)/length(unique(Id)),2))
}
all.chr.counts<-chr_muts(var.2007.8.df)

all.chr.table<-dcast(all.chr.counts,chr~Intervention,value.var="iSNV")
knitr::kable(all.chr.table)
```

Not sure what the NA is we must be missing an intervention somewhere.

High quality data
```{r}
qual.chr.counts<-chr_muts(qual.2007.8)
qual.chr.table<-dcast(qual.chr.counts,chr~Intervention,value.var="iSNV")
knitr::kable(qual.chr.table)

```