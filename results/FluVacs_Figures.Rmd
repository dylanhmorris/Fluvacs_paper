---
title: "FluVacs Figures - Draft"
author: "JT"
date: "June 3, 2016"
output:
  html_document:
    toc: true
    toc_depth: 4
    toc_float: true
    
---

```{r,include=F}
require(knitr)
require(plyr)
require(ggplot2)
require(reshape2)
require(ggplot2)
require(ggdendro)
require(grid)
opts_chunk$set(fig.align="center",warning=FALSE,tidy=T,cache = T,echo=F)
theme_set(new = theme_classic()+ theme(
axis.line.x = element_line(colour = 'black', size=0.5, linetype='solid'),
axis.line.y = element_line(colour = 'black', size=0.5, linetype='solid'))) # to make nice plots
source("../scripts/useful_functions.R") # useful functions adapted largley from HIVE work
```




```{r,titers}
# read in the csvs and add a season column to use later
titer.2004.5<-read.csv("../Titers_status_2004-2005.csv",stringsAsFactors = F)
titer.2004.5$season<-"04-05"
titer.2005.6<-read.csv("../Titers_status_2005-2006.csv",stringsAsFactors = F)
titer.2005.6$season<-"05-06"
titer.2007.8<-read.csv("../Titers_status_2007-2008.csv",stringsAsFactors = F)
titer.2007.8$season<-"07-08"
```

```{r}
meta.2007.08<-read.csv("../data/raw/2007_2008.meta.csv",stringsAsFactors = F)
```

```{r, variant_calls}

var.2007.8<-read.csv("../data/processed/Run_1293/Variants/all.sum.csv",stringsAsFactors = F)
x<-read.csv("../data/processed/Run_1304/Variants/all.sum.csv",stringsAsFactors = F) # the rest of these samples
var.2007.8<-rbind(var.2007.8,x) # combine both runs
#other.seasons<-read.csv("../data/processed/Run_1412/Variants/all.sum.csv",stringsAsFactors = F)


# var.2004.5.df<-processing(data.df = other.seasons,meta.df = titer.2004.5,pval = 0.01,phred = 35,mapq = 30,read_cut = c(32,94))
# 
# var.2004.5.df<-subset(var.2004.5.df,season=="04-05")
# var.2005.6.df<-processing(data.df = other.seasons,meta.df = titer.2005.6,pval = 0.01,phred = 35,mapq = 30,read_cut = c(32,94))
# var.2005.6.df<-subset(var.2005.6.df,season=="05-06")
# 
var.2007.8.df<-processing(data.df = var.2007.8,meta.df = meta.2007.08,pval = 0.01,phred = 35,mapq = 30,read_cut = c(32,94))


# all.df<-rbind(var.2004.5.df,var.2005.6.df)
# all.df<-rbind(all.df,var.2007.8.df)
# 
# all.df<-subset(all.df,freq.var>=0.01)
# ##### Now for the duplicate runs #######
# 
# var.2004.5.df2<-read.csv("../data/processed/2004_2005/Variants/all.sum.csv",stringsAsFactors = F)
# var.2004.5.df2<-processing(data.df = var.2004.5.df2,meta.df = titer.2004.5,pval = 0.01,phred = 35,mapq = 30,read_cut = c(32,94))
# 
# var.2005.6.df2<-read.csv("../data/processed/2005-2006/Variants/all.sum.csv",stringsAsFactors = F)
# var.2005.6.df2<-processing(data.df = var.2005.6.df2,meta.df = titer.2005.6,pval = 0.01,phred = 35,mapq = 30,read_cut = c(32,94))

var.2007.8.df2<-read.csv("../data/processed/2007-2008/Variants/all.sum.csv",stringsAsFactors = F)
var.2007.8.df2<-processing(data.df = var.2007.8.df2,meta.df = meta.2007.08,pval = 0.01,phred = 35,mapq = 30,read_cut = c(32,94))

### Join duplicates #####

# dups.2004.5<-join_dups(data1.df = var.2004.5.df,data2.df = var.2004.5.df2)
# dups.2005.6<-join_dups(data1.df = var.2005.6.df,data2.df = var.2005.6.df2)
dups.2007.8<-join_dups(data1.df = var.2007.8.df,data2.df = var.2007.8.df2)

##### Merge duplicates with intial data that was >1e5

# qual.2004.5<-high_qual(data1.df = var.2004.5.df,dups.df = dups.2004.5,titer = 1e3) # only duplicates above 1e3 kept
# qual.2005.6<-high_qual(data1.df = var.2005.6.df,dups.df = dups.2005.6,titer = 1e3)
qual.2007.8<-high_qual(data1.df = var.2007.8.df,dups.df = dups.2007.8,titer = 1e3)
# all.qual.df<-rbind(qual.2004.5,qual.2005.6)
# all.qual.df<-rbind(all.qual.df,qual.2007.8)
# 
# all.qual.df<-subset(all.qual.df,freq.var>=0.01 & freq.var<=0.99)

var.2007.8.df<-subset(var.2007.8.df,freq.var>=0.01 & freq.var<=0.99)
qual.2007.8<-subset(qual.2007.8,freq.var>=0.01 & freq.var<=0.99)

```

```{r}
gm_mean = function(x, na.rm=TRUE, zero.propagate = FALSE){ # from http://stackoverflow.com/questions/2602583/geometric-mean-is-there-a-built-in
  if(any(x < 0, na.rm = TRUE)){
    return(NaN)
  }
  if(zero.propagate){
    if(any(x == 0, na.rm = TRUE)){
      return(0)
    }
    exp(mean(log(x), na.rm = na.rm))
  } else {
    exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
  }
}

var.2007.8.df<-mutate(var.2007.8.df,responder.HA=HAI.WI.30.post.vax>40,responder.NA=NAI.WI.30.post.vax>40,HAI.geo=HAI.WI.30.post.vax>gm_mean(HAI.WI.30.post.vax),NAI.geo=NAI.WI.30.post.vax>gm_mean(NAI.WI.30.post.vax),responder.both=(responder.NA&responder.HA==T), geom.both=(HAI.geo&NAI.geo==T))

qual.2007.8<-mutate(qual.2007.8,responder.HA=HAI.WI.30.post.vax>40,responder.NA=NAI.WI.30.post.vax>40,HAI.geo=HAI.WI.30.post.vax>gm_mean(HAI.WI.30.post.vax),NAI.geo=NAI.WI.30.post.vax>gm_mean(NAI.WI.30.post.vax),responder.both=(responder.NA&responder.HA==T), geom.both=(HAI.geo&NAI.geo==T))

### For consensus seqeunce meta data
# meta.df<-mutate(meta.2007.08,HAI.geo=HAI.WI.30.post.vax>gm_mean(HAI.WI.30.post.vax),collection_date=)
# meta.df$collection_date<-as.Date(meta.df$collection_date,format = "%d-%b-%y")
# require(lubridate)
# meta.df$collection_date<-decimal_date(meta.df$collection_date)
# 
# 
# 
# write.csv(meta.df,"../data/raw/2007_2008.meta.HAgm.csv")
```

```{r,eval=F}
# This makes the meta data for each sample. I'm doing this for all samples

meta_data<-subset(var.2007.8.df,select=c(Id,mutation,Copy_num,Vax,season,Intervention,HAI.Uruguay.preseason,HAI.Uruaguay.30.post.vax,HAI.WI.vax.preseason,HAI.WI.30.post.vax,NAI.WI.vax.preseason,NAI.WI.30.post.vax,Day.of.Infection.sample.collected,responder.HA,responder.NA,HAI.geo,NAI.geo,responder.both,geom.both))


meta_data<-ddply(meta_data,~Id,function(x) x[1,])
```

#Figure 3 Coverage plots

These are just from the first runs. I'm not including the duplicates here - should I? These have a sliding window of 100 with a step of 100 no overlap.

```{r,coverage}
cov.2007.8<-rbind(read.csv("../data/processed/Run_1293/deepSNV/all.coverage.csv",stringsAsFactors = F),read.csv("../data/processed/Run_1304/deepSNV/all.coverage.csv",stringsAsFactors = F))

other.seasons.cov<-read.csv("../data/processed/Run_1412/deepSNV/all.coverage.csv",stringsAsFactors = F)


cov.2004.5<-subset(other.seasons.cov,Id %in% titer.2004.5$Sample)
cov.2005.6<-subset(other.seasons.cov,Id %in% titer.2005.6$Sample)


cov.plot.04.05<-cov_plot(cov.2004.5,"2004-2005",100,100)
cov.plot.04.05

cov.plot.05.06<-cov_plot(cov.2005.6,"2005-2006",100,100)
cov.plot.05.06

cov.plot.07.08<-cov_plot(cov.2007.8,"2007-2008",100,100)
cov.plot.07.08

```

If we plot on a log scale the bars are well above 0. 

```{r}
cov.plot.07.08+scale_y_log10(breaks=c(1,10,100,1000,10000,100000))
```


I have made the following figures using just thevariant data from the 2007-2008 season. This constitutes the majority of the sequenced data. If we want to include the other seasons we'll just need to incorporate the HAI and NAI titers and sample day in the meta data. I have only included variants between 1-99% frequency.

# Figure 5 

High quality is >10^5^ or >10^3^ sequenced in duplicate.
Currently I am making these plots with just the 2007-2008 samples. Once I have the meta datafor the other seasons it will be trivial to add them (if we want to do that) 

## Frequency of Variants

These are the variants between 1-50%. each bin is 1% wide. The y axis is log scaled which in ggplot leads to a problem when there are no observations (lines below axis). I can remove these before publication.
```{r}
ggplot(subset(var.2007.8.df,freq.var<=0.5),aes(x=freq.var))+geom_histogram(color="white",binwidth = 0.01)#+scale_y_log10() + ggtitle("All samples")
ggplot(subset(qual.2007.8,freq.var<=0.5),aes(x=freq.var))+geom_histogram(color="white",binwidth = 0.01)+xlab("Frequency")+ylab("Number of SNV")

```

### iSNV

We are only counting variants between 1% and 50%.

#### By day

```{r,by_day}
isnv_day<-function(df){
  df<-subset(df,freq.var<=0.5)
  ddply(df,~Id+Day.of.Infection.sample.collected+Intervention,summarize,iSNV=length(mutation))
}

#all.isnv.day<-isnv_day(var.2007.8.df)
#all.isnv.day$data="All"
qual.isnv.day<-isnv_day(qual.2007.8)
#qual.isnv.day$data="High Quality"

#all.data.isnv.day<-rbind(all.isnv.day,qual.isnv.day)
qual.isnv.day<-rbind(qual.isnv.day,data.frame(Id=rep("extra",3),Day.of.Infection.sample.collected=c(5,6,6),Intervention=c("IIV","IIV","LAIV"),iSNV=rep(NA,3))) # this keeps everything in order. We don't had data for these days and interventions


iSNV.day<-ggplot(data=qual.isnv.day,aes(y=iSNV,x=as.factor(paste(Day.of.Infection.sample.collected,Intervention,sep="_"))))+geom_dotplot(aes(fill=Intervention),stackdir = "center",binaxis = 'y',position='dodge',binwidth = 1,dotsize = 0.7)+ylab("Number of SNV")+ggtitle("iSNV by day")+xlab("Day of Infection")+stat_summary(fun.y = median, fun.ymin = median, fun.ymax = median,geom = "crossbar", width = 0.5)+scale_y_continuous(limits=c(0,18),breaks=seq(0,18,2))+scale_x_discrete(labels=c("","2","","","3","","","4","","","5","","","6",""))

pdf("~/Box Sync/FluVax Paper/Graphs/iSNV.day.pdf",width=9,height=4)
iSNV.day
dev.off()

```

```{r,by_day.densisty}
H<-function(x){
  H_pos<-ddply(x,~chr+pos,summarize,H=-sum(c(freq.var*log(freq.var))))
sum(H_pos$H)/(13149)
}

entropy_day<-function(df){

  ddply(df,~Id+Day.of.Infection.sample.collected+Intervention,summarize,H=H(data.frame(chr,pos,freq.var)))
  
}


qual.H.day<-entropy_day(qual.2007.8)
qual.H.day<-rbind(qual.H.day,data.frame(Id=rep("extra",3),Day.of.Infection.sample.collected=c(5,6,6),Intervention=c("IIV","IIV","LAIV"),H=rep(NA,3))) # this keeps everything in order. We don't had data for these days and interventions

H.day<-ggplot(data=qual.H.day,aes(y=H,x=as.factor(paste(Day.of.Infection.sample.collected,Intervention,sep="_"))))+geom_dotplot(aes(fill=Intervention),stackdir = "center",binaxis = 'y',position='dodge')+stat_summary(fun.y = median, fun.ymin = median, fun.ymax = median,geom = "crossbar", width = 0.5)+scale_x_discrete(labels=c("","2","","","3","","","4","","","5","","","6",""))+ylab("Entropy per genomic site")+ggtitle("Entropy by day")+xlab("Day of Infection")

pdf("~/Box Sync/FluVax Paper/Graphs/H.day.pdf",width=7,height=3)
H.day
dev.off()

```


```{r}
require(cowplot)

x<-plot_grid(iSNV.day, H.day, labels = c("A", "B"))

pdf("~/Desktop/HIVE_grant.pdf",width = 12,height = 3.5)
x
dev.off()
```
It looks like the iSNV count peaks around day 3 or 4. But I don't know if that's statistically significant or robust.


```{r,snv_sample}
count_muts<-function(data.df){
  data.df<-subset(data.df,freq.var<=0.5)
  inter<-ddply(data.df,~Id+Intervention+season,summarize,iSNV=length(mutation))
  inter$variable="Intervention"
  names(inter)[2]<-"quality"
  
  HA.r<-ddply(data.df,~Id+responder.HA+season,summarize,iSNV=length(mutation))
  HA.r$variable='responder (HA)'
  names(HA.r)[2]<-"quality"
  out<-rbind(inter,HA.r)
  
  NA.r<-ddply(data.df,~Id+responder.NA+season,summarize,iSNV=length(mutation))
  NA.r$variable="responder (NA)"
  names(NA.r)[2]<-"quality"
  out<-rbind(out,NA.r)
  
  HA.geo<-ddply(data.df,~Id+HAI.geo+season,summarize,iSNV=length(mutation))
  HA.geo$variable="above geometric mean (HA)"
  names(HA.geo)[2]<-"quality"
  out<-rbind(out,HA.geo)
  
  NA.geo<-ddply(data.df,~Id+NAI.geo+season,summarize,iSNV=length(mutation))
  NA.geo$variable<-"above geometric mean (NA)"
  names(NA.geo)[2]<-"quality"
  out<-rbind(out,NA.geo)
  
  both.responder<-ddply(data.df,~Id+responder.both+season,summarize,iSNV=length(mutation))
  both.responder$variable<-"responder (HA & NA)"
  names(both.responder)[2]<-"quality"
  out<-rbind(out,both.responder)
  
  both.geo<-ddply(data.df,~Id+geom.both+season,summarize,iSNV=length(mutation))
  both.geo$variable<-"above geometric mean  (HA & NA)"
  names(both.geo)[2]<-"quality"
  out<-rbind(out,both.geo)
  
  
}


all.snv<-count_muts(var.2007.8.df)
qual.snv<-count_muts(qual.2007.8)

all.snv$data="All"
qual.snv$data="High Quality"
all.data.snv<-rbind(all.snv,qual.snv)


```
#### Whole Genome

```{r}
dot_plots<-function(df,var,title){
data<-subset(df,variable==var & data=="High Quality")
means<-ddply(data,~quality,summarize,iSNV=median(iSNV))
out<-ggplot()+geom_point(data=means,aes(y=iSNV,x=quality),shape=95,size=20,col='red')+geom_dotplot(data=data,aes(y=iSNV,x=quality),stackdir = "center",binaxis = 'y',dotsize = 0.5)+ylab("Number of SNV")+ggtitle(title)+xlab(var)+facet_wrap(~data)
print(out)
print(kable(data))
sumup<-ddply(data,~quality,summarize,samples=length(Id),average_snv=mean(iSNV))
kable(sumup)
}


dot_plots(all.data.snv,"Intervention","Vaccine status")


dot_plots(all.data.snv,"above geometric mean (HA)","above geometric mean (HA)")


```

### HA NA

```{r}
all.ha.na.snv<-count_muts(subset(var.2007.8.df,chr %in%c("HA","N_A","NR")))
qual.ha.na.snv<-count_muts(subset(qual.2007.8,chr %in%c("HA","N_A","NR")))

all.ha.na.snv$data="All"
qual.ha.na.snv$data="High Quality"

all.data.ha.na.snv<-rbind(all.ha.na.snv,qual.ha.na.snv)

dot_plots(all.data.ha.na.snv,"Intervention","All Data HA & NA")
```

# Table 4
Average iSNV/ segment

All data 
```{r}
chr_muts<-function(data.df){
  data.df<-subset(data.df,freq.var<=0.5)
  ddply(data.df,~Intervention+chr,summarize,iSNV=round(length(mutation)/length(unique(Id)),2))
}
all.chr.counts<-chr_muts(var.2007.8.df)

all.chr.table<-dcast(all.chr.counts,chr~Intervention,value.var="iSNV")
knitr::kable(all.chr.table)
```

Not sure what the NA is we must be missing an intervention for one of the samples.

High quality data
```{r}
qual.chr.counts<-chr_muts(qual.2007.8)
qual.chr.table<-dcast(qual.chr.counts,chr~Intervention,value.var="iSNV")
knitr::kable(qual.chr.table)

```


# Appendix
## Linear plots

```{r}
count_muts_samples<-function(data.df){
  data.df<-subset(data.df,freq.var<=0.5)
  out<-ddply(data.df,~Id,summarize,muts=length(mutation),HAI.WI=HAI.WI.30.post.vax[1],NAI.WI=NAI.WI.30.post.vax[1],Copy_num=Copy_num[1],dpi=Day.of.Infection.sample.collected[1])
}

lines.07<-count_muts_samples(qual.2007.8)


ggplot(lines.07,aes(y=muts,x=Copy_num))+geom_point()
ggplot(lines.07,aes(y=muts,x=HAI.WI))+geom_point()
ggplot(lines.07,aes(y=muts,x=NAI.WI))+geom_point()
ggplot(lines.07,aes(y=muts,x=dpi))+geom_point()


```

## Linear model with all variables

NB : I'm not sure what I'm doing here and if it's valid.

```{r}
model<-lm(lines.07$muts~lines.07$HAI.WI+lines.07$NAI.WI+lines.07$Copy_num+lines.07$dpi)

summary(model)

```

I think this means that maybe the copy number is the only variable that affects the iSNV count. What if we remove the one outlier at 16.
```{r}
no_out.07<-subset(lines.07,muts!=16)

model.no<-lm(no_out.07$muts~no_out.07$HAI.WI+no_out.07$NAI.WI+no_out.07$Copy_num+no_out.07$dpi)

summary(model.no)

```

Yep. I looks like that was driving things. 

I'll have to think about whether or not this analysis is justified, valid, and needed.


## Extra iSNV groupings
### Whole genome
```{r,extra_iSNV}
dot_plots(all.data.snv,"responder (HA)","HA responders")
dot_plots(all.data.snv,"responder (NA)","NA responders")
dot_plots(all.data.snv,"above geometric mean (HA)","Relative HA groups")
dot_plots(all.data.snv,"above geometric mean (NA)","Relative NA groups")
dot_plots(all.data.snv,"responder (HA & NA)","HA and NA responders")
dot_plots(all.data.snv,"above geometric mean  (HA & NA)","Relative HA & NA groups")
```

### HA and NA

```{r,extra_ha.na}
dot_plots(all.data.ha.na.snv,"responder (HA)","All Data HA & NA")
dot_plots(all.data.ha.na.snv,"responder (NA)","All Data HA & NA")
dot_plots(all.data.ha.na.snv,"above geometric mean (HA)","All Data HA & NA")
dot_plots(all.data.ha.na.snv,"above geometric mean (NA)","All Data HA & NA")
dot_plots(all.data.ha.na.snv,"responder (HA & NA)","All Data HA & NA")
dot_plots(all.data.ha.na.snv,"above geometric mean  (HA & NA)","All Data HA & NA")
```


```{r,eval=T}
## Getting data for HA
ha<-subset(qual.2007.8,chr=='HA')
dim(ha)
ha<-ha[order(ha$pos),]
unique(ha$pos)
write.csv(x = ha,file="../data/2007_2008.ha.csv",row.names = F)


```


```{r,table_for_stats}

qual.2007.8


```



